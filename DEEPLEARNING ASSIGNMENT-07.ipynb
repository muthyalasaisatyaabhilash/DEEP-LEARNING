{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf3bceb3",
   "metadata": {},
   "source": [
    "\n",
    "# DEEPLEARNING ASSIGNMENT-07"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897279bf",
   "metadata": {},
   "source": [
    "1. Can you think of a few applications for a sequence-to-sequence RNN? What about a\n",
    "sequence-to-vector RNN, and a vector-to-sequence RNN?\n",
    "2. How many dimensions must the inputs of an RNN layer have? What does each dimension\n",
    "represent? What about its outputs?\n",
    "3. If you want to build a deep sequence-to-sequence RNN, which RNN layers should\n",
    "have return_sequences=True? What about a sequence-to-vector RNN?\n",
    "4. Suppose you have a daily univariate time series, and you want to forecast the next seven\n",
    "days. Which RNN architecture should you use?\n",
    "5. What are the main difficulties when training RNNs? How can you handle them?\n",
    "6. Can you sketch the LSTM cell’s architecture?\n",
    "7. Why would you want to use 1D convolutional layers in an RNN?\n",
    "8. Which neural network architecture could you use to classify videos?\n",
    "9. Train a classification model for the SketchRNN dataset, available in TensorFlow Datasets."
   ]
  },
  {
   "cell_type": "raw",
   "id": "7854e6c9",
   "metadata": {},
   "source": [
    "1A) Applications for sequence-to-sequence RNNs include language translation, speech recognition, and image captioning. Sequence-to-vector RNNs are often used for sentiment analysis, where the input is a sentence and the output is a single value representing the sentiment. Vector-to-sequence RNNs can be used for tasks such as generating a sentence or a musical composition from a given vector.\n",
    "\n",
    "2A)The inputs to an RNN layer have three dimensions: (batch_size, sequence_length, input_features). The batch size represents the number of samples processed at once, the sequence length is the length of each input sequence, and the input features represent the number of features in each input vector. The outputs of an RNN layer have two dimensions: (batch_size, output_features), where output features represent the number of features in the output vector.\n",
    "\n",
    "3A)In a deep sequence-to-sequence RNN, all RNN layers except for the last one should have return_sequences=True to output a sequence. In a sequence-to-vector RNN, only the last RNN layer should have return_sequences=False to output a single vector.\n",
    "\n",
    "4A)For forecasting the next seven days of a daily univariate time series, a type of RNN called a \"sequence-to-sequence with encoder-decoder architecture\" should be used. This architecture can take the entire input sequence as input and output a sequence of the same length with the predictions for the next seven days.\n",
    "\n",
    "5)The main difficulties when training RNNs include vanishing gradients, exploding gradients, and overfitting. These can be handled by using techniques such as gradient clipping, regularization, and early stopping.\n",
    "\n",
    "6)The LSTM cell's architecture includes an input gate, a forget gate, an output gate, and a memory cell. The input gate controls the amount of new input that is added to the memory cell, the forget gate controls the amount of information that is removed from the memory cell, and the output gate controls the amount of output that is generated based on the memory cell.\n",
    "\n",
    "7)1D convolutional layers can be used in an RNN to extract higher-level features from the input sequence before passing it to the RNN. This can improve the performance of the RNN by reducing the amount of noise and irrelevant information in the input.\n",
    "\n",
    "8)A popular neural network architecture for classifying videos is the 3D convolutional neural network (CNN). This architecture extends the 2D CNN by adding a temporal dimension, allowing it to analyze the temporal information in a video."
   ]
  },
  {
   "cell_type": "raw",
   "id": "179f000f",
   "metadata": {},
   "source": [
    "9A)Here's an example of how to train a classification model for the SketchRNN dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cca0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the SketchRNN dataset\n",
    "data, info = tfds.load('sketch_rnn/quickdraw', split='train[:80%]', with_info=True)\n",
    "\n",
    "# Preprocess the data\n",
    "def preprocess(data):\n",
    "    # Convert the input strokes to a tensor\n",
    "    strokes = tf.cast(data['drawing'], tf.float32)\n",
    "    # Normalize the strokes to have zero mean and unit variance\n",
    "    strokes -= tf.reduce_mean(strokes, axis=(0, 1))\n",
    "    strokes /= tf.math.reduce_std(strokes)\n",
    "    # Convert the label to a one-hot encoding\n",
    "    label = tf.one_hot(data['label'], depth=345)\n",
    "    return strokes, label\n",
    "\n",
    "data = data.map(preprocess)\n",
    "\n",
    "# Define the model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=(None, 3)),\n",
    "    tf.keras.layers.LSTM\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
