{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d8b3bd8",
   "metadata": {},
   "source": [
    "# DEEPLEARNING ASSIGNMENT-06\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09b36ec",
   "metadata": {},
   "source": [
    "1. What are the advantages of a CNN over a fully connected DNN for image classification?\n",
    "2. Consider a CNN composed of three convolutional layers, each with 3 × 3 kernels, a stride of\n",
    "2, and &quot;same&quot; padding. The lowest layer outputs 100 feature maps, the middle one outputs\n",
    "200, and the top one outputs 400. The input images are RGB images of 200 × 300 pixels.\n",
    "What is the total number of parameters in the CNN? If we are using 32-bit floats, at least how much\n",
    "RAM will this network require when making a prediction for a single instance? What about when\n",
    "training on a mini-batch of 50 images?\n",
    "3. If your GPU runs out of memory while training a CNN, what are five things you could try to\n",
    "solve the problem?\n",
    "4. Why would you want to add a max pooling layer rather than a convolutional layer with the\n",
    "same stride?\n",
    "5. When would you want to add a local response normalization layer?\n",
    "6. Can you name the main innovations in AlexNet, compared to LeNet-5? What about the main\n",
    "innovations in GoogLeNet, ResNet, SENet, and Xception?\n",
    "7. What is a fully convolutional network? How can you convert a dense layer into a\n",
    "convolutional layer?\n",
    "8. What is the main technical difficulty of semantic segmentation?\n",
    "9. Build your own CNN from scratch and try to achieve the highest possible accuracy on MNIST.\n",
    "10. Use transfer learning for large image classification, going through these steps:\n",
    "a. Create a training set containing at least 100 images per class. For example, you could\n",
    "classify your own pictures based on the location (beach, mountain, city, etc.), or\n",
    "alternatively you can use an existing dataset (e.g., from TensorFlow Datasets).\n",
    "b. Split it into a training set, a validation set, and a test set.\n",
    "c. Build the input pipeline, including the appropriate preprocessing operations, and\n",
    "optionally add data augmentation.\n",
    "d. Fine-tune a pretrained model on this dataset."
   ]
  },
  {
   "cell_type": "raw",
   "id": "5b554147",
   "metadata": {},
   "source": [
    "1. Advantages of CNN over fully connected DNN for image classification:\n",
    "CNNs are designed to handle 2D image data and are better suited to capturing spatial features like edges, corners, and textures.\n",
    "CNNs use shared weights and local receptive fields, allowing them to efficiently learn hierarchical representations of image data.\n",
    "CNNs have fewer parameters than fully connected DNNs, making them easier to train and less prone to overfitting.\n",
    "\n",
    "\n",
    "2. Total number of parameters in the CNN:\n",
    "The first convolutional layer has 3 * 3 * 3 * 100 = 2,700 parameters (3 * 3 * 3 kernel size, 100 output feature maps, and 3 input channels for RGB images)\n",
    "The second convolutional layer has 3 * 3 * 100 * 200 = 1,800,000 parameters (3 * 3 * 100 kernel size, 200 output feature maps, and 100 input feature maps)\n",
    "The third convolutional layer has 3 * 3 * 200 * 400 = 14,400,000 parameters (3 * 3 * 200 kernel size, 400 output feature maps, and 200 input feature maps)\n",
    "The fully connected layer has 400 * 2,000 = 800,000 parameters (400 input features and 2,000 output features)\n",
    "Total number of parameters = 2,700 + 1,800,000 + 14,400,000 + 800,000 = 17,003,700\n",
    "RAM required for a single instance:\n",
    "\n",
    "Each instance is a 200 x 300 RGB image, so the input size is 200 x 300 x 3 = 180,000.\n",
    "For each convolutional layer, the output size is 100 x 100 x 100, 50 x 75 x 200, and 25 x 38 x 400, respectively.\n",
    "Assuming 32-bit floats, each parameter requires 4 bytes of memory, so the total memory required for the parameters is 68 MB.\n",
    "For inference, we only need to store the output of the convolutional layers, which is 47.5 MB per instance (100 x 100 x 100 + 50 x 75 x 200 + 25 x 38 x 400) plus the memory for the fully connected layer.\n",
    "So, the total RAM required for a single instance during inference is approximately 48 MB.\n",
    "For training on a mini-batch of 50 images, we need to store the intermediate activations and gradients, so the total RAM required would be much higher, depending on the batch size and the size of the model.\n",
    " \n",
    " \n",
    " 3.Five things to try if GPU runs out of memory while training a CNN:\n",
    "Reduce the batch size: This reduces the amount of memory required for each batch of data.\n",
    "Reduce the size of the model: This reduces the number of parameters and intermediate activations, reducing the amount of memory required.\n",
    "Use mixed precision training: This uses lower precision (e.g., float16) for some or all of the model's parameters and activations, reducing the amount of memory required.\n",
    "Use gradient checkpointing: This reduces the amount of memory required for storing intermediate activations during backpropagation.\n",
    "Use data parallelism: This divides the batch among multiple GPUs, reducing the amount of memory required on each GPU.\n",
    "\n",
    "\n",
    "4.   Advantages of adding a max pooling layer rather than a convolutional layer with the same stride:\n",
    "Max pooling reduces the spatial size of the input, while preserving the depth (number of channels).\n",
    "Max pooling helps to reduce overfitting, as it introduces some degree of translation invariance into the model.\n",
    "\n",
    "\n",
    "5.  Local response normalization (LRN) layers were commonly used in older CNN architectures such as AlexNet, but are less frequently used now. The main purpose of LRN layers is to normalize the activations across neighboring feature maps in the same layer. This can help to increase the model's ability to generalize to new images by reducing the likelihood of overfitting to specific patterns in the training data. However, LRN layers can also be computationally expensive and may not always improve performance.\n",
    "\n",
    "6.  AlexNet introduced several key innovations compared to LeNet-5, including the use of ReLU activation functions, dropout regularization, data augmentation, and parallelizable GPU implementation. GoogLeNet introduced the concept of \"inception modules,\" which allow for the use of multiple filter sizes and pooling operations in the same layer. ResNet introduced residual connections, which allow for the training of very deep networks by enabling information to flow through skip connections that bypass several layers at once. SENet introduced the concept of \"squeeze-and-excitation\" blocks, which learn to weight feature maps based on their importance. Xception uses depthwise separable convolutions, which factorize standard convolutions into separate depthwise and pointwise convolutions to reduce the number of parameters and improve performance.\n",
    "\n",
    "7.  A fully convolutional network (FCN) is a type of CNN that is designed for dense pixel-wise prediction tasks, such as semantic segmentation. Rather than using fully connected layers at the end of the network to produce a single output, an FCN uses convolutional layers that output a spatial grid of predictions. To convert a dense layer into a convolutional layer, you can reshape the weights of the dense layer into a 4D tensor with shape (kernel_size, kernel_size, input_channels, output_channels), where kernel_size is typically 1 (for a global average pooling layer) or equal to the width and height of the input feature maps (for a fully connected layer).\n",
    "\n",
    "8.  The main technical difficulty of semantic segmentation is that it requires dense pixel-wise predictions, which can be computationally expensive and memory-intensive. Additionally, semantic segmentation often requires the network to learn fine-grained distinctions between classes, which can be challenging when there is significant intra-class variation or when classes are visually similar\n",
    "\n",
    "9.Here is an example of a simple CNN architecture for MNIST:\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels))\n",
    "This model has three convolutional layers with increasing numbers of filters, followed by two dense layers. The final dense layer has 10 units (one for each MNIST digit class) and no activation function, since we will use the logits as the model's output. This architecture achieves an accuracy of around 99% on the MNIST test set after 10 epochs of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7504a7a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
